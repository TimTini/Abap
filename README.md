# ABAP → Excel Template Tool (offline)

Workflow:
1) Open `viewer/index.html` (offline) → paste ABAP → optionally edit descriptions → Export XML
2) Paste the XML into Excel and run `excel/modAbapTemplateTool.bas` to generate templates

## Viewer (offline)
- Open: `viewer/index.html`
- Optional single-file build: `python scripts/build-inline-viewer.py` → `viewer/index.inline.html`
- Input: paste ABAP (or JSON output from CLI) and click **Render**
- Optional:
  - **Descriptions**: edit variable descriptions (saved in browser localStorage)
  - **Rules**: create/save custom parsing rules (saved in browser localStorage)
- Output: **Export XML** → paste into Excel

## Excel (VBA)
- VBA module: `excel/modAbapTemplateTool.bas`
- Expected XML root: `<abapflowObjects>` (generated by the viewer)
- Runtime test (requires Excel Desktop + VBA project access enabled):
  - `powershell -ExecutionPolicy Bypass -File scripts/run-vba-runtime-tests.ps1`
  - Optional skip on machines without Excel: `powershell -ExecutionPolicy Bypass -File scripts/run-vba-runtime-tests.ps1 -SkipIfExcelMissing`

## Add / change statement rules (single source of truth)
- Source rules: `configs/*.json`
- Regenerate viewer configs after editing rules:
  - `node scripts/build-viewer-configs.js`
- Viewer consumes the generated files: `viewer/configs.generated/*.js`
- Guide: `RULES.md`

## CLI (optional)
- Parse ABAP file to JSON:
  - `node cli/parse.js <file.abap>`

## AI / Agent notes
- Local agent guide: `AGENTS.md`
- Purpose: keep parser/output behavior consistent across different AI agents and avoid regressions.
- Minimum check before finishing changes:
  - `node tests/parser-regression.js`
  - If viewer changed: `python scripts/build-inline-viewer.py`

## Examples
- Full coverage sample: `examples/full.abap`
- More samples: `examples/*.abap`
